{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "from pathlib import Path\n",
    "from src.laptop_price_prediction.constants.constant import *\n",
    "from src.laptop_price_prediction.utils.common import read_yaml, create_directories, read_sql\n",
    "from src.laptop_price_prediction.logger import logging\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    raw_path: Path\n",
    "    train_path: Path\n",
    "    test_path: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_file_path = CONFIG_FILE_PATH):\n",
    "        \n",
    "\n",
    "        try:\n",
    "            self.config = read_yaml(config_file_path)\n",
    "            logging.info(f\"Configuration file loaded successfully\")\n",
    "\n",
    "            logging.info(f'Creating directories to stor artifacts')\n",
    "            create_directories([self.config.artifacts])\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading configuration file: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        try:\n",
    "            config = self.config.data_ingestion\n",
    "            logging.info(f\"Data Ingestion Configuration loaded successfully\")\n",
    "\n",
    "            logging.info(f\"Creating directories to store data\")\n",
    "            create_directories([config.root_dir])\n",
    "\n",
    "            logging.info(f\"Successfully created directories to store data\")\n",
    "\n",
    "            logging.info(f\"Assigning paths to raw, train and test data\")\n",
    "            \n",
    "            data_ingestion_config = DataIngestionConfig(\n",
    "                raw_path = config.raw_path,\n",
    "                train_path = config.train_path,\n",
    "                test_path = config.test_path\n",
    "            )\n",
    "\n",
    "            logging.info(f\"Paths assigned successfully\")\n",
    "            \n",
    "            return data_ingestion_config\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading data ingestion configuration: {e}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def initiate_data_ingestion(self) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "        try:\n",
    "            df = read_sql()\n",
    "\n",
    "            logging.info(f\"Data loaded successfully\")\n",
    "            df.to_csv(self.config.raw_path, index=False, header=True)\n",
    "\n",
    "            logging.info(f\"Data saved successfully\")\n",
    "\n",
    "            logging.info(f\"Splitting data into train and test data\")\n",
    "            train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "            logging.info(f\"Data split successfully\")\n",
    "\n",
    "            train_data.to_csv(self.config.train_path, index=False, header=True)\n",
    "            test_data.to_csv(self.config.test_path, index=False, header=True)\n",
    "\n",
    "            logging.info(f\"Train and Test data saved successfully\")\n",
    "\n",
    "            return (\n",
    "                self.config.train_path,\n",
    "                self.config.test_path\n",
    "            )\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in data ingestion: {e}\")\n",
    "            raise e\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2024-10-05 16:39:48,698 ] 20 root - INFO - Configuration file loaded successfully\n",
      "[ 2024-10-05 16:39:48,699 ] 20 root - INFO - Creating directories to stor artifacts\n",
      "[ 2024-10-05 16:39:48,700 ] 20 root - INFO - Creating directories\n",
      "[ 2024-10-05 16:39:48,701 ] 20 root - INFO - Directories created successfully\n",
      "[ 2024-10-05 16:39:48,701 ] 20 root - INFO - Data Ingestion Configuration loaded successfully\n",
      "[ 2024-10-05 16:39:48,702 ] 20 root - INFO - Creating directories to store data\n",
      "[ 2024-10-05 16:39:48,703 ] 20 root - INFO - Creating directories\n",
      "[ 2024-10-05 16:39:48,704 ] 20 root - INFO - Directories created successfully\n",
      "[ 2024-10-05 16:39:48,704 ] 20 root - INFO - Successfully created directories to store data\n",
      "[ 2024-10-05 16:39:48,705 ] 20 root - INFO - Assigning paths to raw, train and test data\n",
      "[ 2024-10-05 16:39:48,705 ] 20 root - INFO - Paths assigned successfully\n",
      "[ 2024-10-05 16:39:48,706 ] 20 root - INFO - Creating connection to MySQL database\n",
      "[ 2024-10-05 16:39:48,712 ] 20 root - INFO - Reading data from MySQL database\n",
      "[ 2024-10-05 16:39:48,724 ] 20 root - INFO - Data read successfully\n",
      "[ 2024-10-05 16:39:48,725 ] 20 root - INFO - Data loaded successfully\n",
      "[ 2024-10-05 16:39:48,735 ] 20 root - INFO - Data saved successfully\n",
      "[ 2024-10-05 16:39:48,736 ] 20 root - INFO - Splitting data into train and test data\n",
      "[ 2024-10-05 16:39:48,739 ] 20 root - INFO - Data split successfully\n",
      "[ 2024-10-05 16:39:48,751 ] 20 root - INFO - Train and Test data saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\OneDrive - Sujal Dhungana\\Laptop Price Prediction\\src\\laptop_price_prediction\\utils\\common.py:38: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query('SELECT * FROM laptop', conn)\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        config_manager = ConfigurationManager()\n",
    "        data_ingestion_config = config_manager.get_data_ingestion_config()\n",
    "        data_ingestion = DataIngestion(data_ingestion_config)\n",
    "        data_ingestion.initiate_data_ingestion()\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error: {e}')\n",
    "        logging.error(traceback.format_exc())\n",
    "        raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laptop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
